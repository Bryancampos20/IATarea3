{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: What time do you close?\n",
      "Respuesta seleccionada: We are open from 10 AM to 10 PM. (Similitud: 0.59)\n",
      "\n",
      "Pregunta: Can I pay with a credit card?\n",
      "Respuesta seleccionada: You can pay with credit card, cash, or mobile payment. (Similitud: 0.79)\n",
      "\n",
      "Pregunta: What sizes do your pizzas come in?\n",
      "Respuesta seleccionada: Our pizzas come in three sizes: small, medium, and large. (Similitud: 0.44)\n",
      "\n",
      "Pregunta: Do you deliver?\n",
      "Respuesta seleccionada: We offer delivery services from 11 AM to 9 PM. (Similitud: 0.53)\n",
      "\n",
      "Pregunta: Do you offer gluten-free pizzas?\n",
      "Respuesta seleccionada: Yes, we have gluten-free pizza options. (Similitud: 0.82)\n",
      "\n",
      "Pregunta: How can I contact you?\n",
      "Respuesta seleccionada: You can call us at 123-456-7890. (Similitud: 0.39)\n",
      "\n",
      "Pregunta: What is your best-selling pizza?\n",
      "Respuesta seleccionada: Our most popular pizza is the Margherita. (Similitud: 0.74)\n",
      "\n",
      "Pregunta: Where are you located?\n",
      "Respuesta seleccionada: We are located at 123 Main Street. (Similitud: 0.41)\n",
      "\n",
      "Pregunta: Where can I see your menu?\n",
      "Respuesta seleccionada: You can find our menu online on our website. (Similitud: 0.44)\n",
      "\n",
      "Pregunta: Do you have vegan options?\n",
      "Respuesta seleccionada: We do offer vegan cheese for our pizzas. (Similitud: 0.56)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cargar el modelo de spaCy para generar embeddings\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Definir las respuestas\n",
    "respuestas_larga = [\n",
    "    \"We are open from 10 AM to 10 PM.\",\n",
    "    \"You can pay with credit card, cash, or mobile payment.\",\n",
    "    \"Our pizzas come in three sizes: small, medium, and large.\",\n",
    "    \"We offer delivery services from 11 AM to 9 PM.\",\n",
    "    \"Yes, we have gluten-free pizza options.\",\n",
    "    \"You can call us at 123-456-7890.\",\n",
    "    \"Our most popular pizza is the Margherita.\",\n",
    "    \"We are located at 123 Main Street.\",\n",
    "    \"You can find our menu online on our website.\",\n",
    "    \"We do offer vegan cheese for our pizzas.\"\n",
    "]\n",
    "\n",
    "# Frases para embeddings\n",
    "respuestas_enveding = [\n",
    "    \"open close schedule\",\n",
    "    \"pay credit card money\",\n",
    "    \"sizes\",\n",
    "    \"delivery deliver\",\n",
    "    \"gluten-free\",\n",
    "    \"call contact\",\n",
    "    \"popular best-selling\",\n",
    "    \"location ubication\",\n",
    "    \"menu online\",\n",
    "    \"vegan\"\n",
    "]\n",
    "\n",
    "# Generar embeddings para las respuestas y normalizarlas\n",
    "embeddings_respuestas = np.array([nlp(respuesta).vector for respuesta in respuestas_enveding])\n",
    "norms_respuestas = np.linalg.norm(embeddings_respuestas, axis=1, keepdims=True)\n",
    "embeddings_respuestas = embeddings_respuestas / norms_respuestas\n",
    "\n",
    "# Palabras \"basura\" a eliminar\n",
    "palabras_basura = [\"what\", \"how\", \"where\", \"when\", \"do\", \"you\", \"can\", \"I\", \"with\", \"a\", \"your\", \"pizza\", \"pizzas\", \"have\"]\n",
    "\n",
    "# Definir las preguntas del usuario\n",
    "preguntas_usuario = [\n",
    "    \"What time do you close?\",\n",
    "    \"Can I pay with a credit card?\",\n",
    "    \"What sizes do your pizzas come in?\",\n",
    "    \"Do you deliver?\",\n",
    "    \"Do you offer gluten-free pizzas?\",\n",
    "    \"How can I contact you?\",\n",
    "    \"What is your best-selling pizza?\",\n",
    "    \"Where are you located?\",\n",
    "    \"Where can I see your menu?\",\n",
    "    \"Do you have vegan options?\"\n",
    "]\n",
    "\n",
    "# Procesar cada pregunta\n",
    "for pregunta in preguntas_usuario:\n",
    "    # Limpiar la pregunta\n",
    "    pregunta_limpia = ' '.join([palabra for palabra in pregunta.lower().split() if palabra not in palabras_basura])\n",
    "    \n",
    "    # Generar embedding para la pregunta limpia\n",
    "    embedding_pregunta = nlp(pregunta_limpia).vector\n",
    "    embedding_pregunta = embedding_pregunta / np.linalg.norm(embedding_pregunta)  # Normalizar el embedding de la pregunta\n",
    "    \n",
    "    # Calcular la similitud de coseno con todas las respuestas\n",
    "    similitudes = cosine_similarity([embedding_pregunta], embeddings_respuestas).flatten()\n",
    "    \n",
    "    # Encontrar el índice de la respuesta más similar\n",
    "    indice_mejor_respuesta = np.argmax(similitudes)\n",
    "    mejor_similitud = similitudes[indice_mejor_respuesta]\n",
    "    \n",
    "    # Verificar si la mejor similitud cumple con el umbral mínimo\n",
    "    umbral_similitud = 0.1  # Ajusta este valor según sea necesario\n",
    "    if mejor_similitud >= umbral_similitud:\n",
    "        respuesta_seleccionada = respuestas_larga[indice_mejor_respuesta]\n",
    "    else:\n",
    "        respuesta_seleccionada = \"I'm sorry, I don't understand your question. Could you rephrase it?\"\n",
    "\n",
    "    print(f\"Pregunta: {pregunta}\")\n",
    "    print(f\"Respuesta seleccionada: {respuesta_seleccionada} (Similitud: {mejor_similitud:.2f})\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
